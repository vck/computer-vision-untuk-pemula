{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Foundations of Computer Vision\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this module, you should be able to:\n",
    "- Understand how digital images are represented\n",
    "- Perform basic image processing operations\n",
    "- Implement edge detection algorithms\n",
    "- Apply thresholding techniques for image segmentation\n",
    "\n",
    "## Topics Covered\n",
    "- Image representation and formats\n",
    "- Basic image processing operations\n",
    "- Color spaces (RGB, HSV, Grayscale)\n",
    "- Image filtering and convolution\n",
    "- Edge detection (Sobel, Canny)\n",
    "- Histograms and thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Representation and Formats\n",
    "\n",
    "Digital images are represented as matrices of pixel values. Each pixel has:\n",
    "- Position (x, y coordinates)\n",
    "- Value (intensity or color)\n",
    "\n",
    "### Image Types\n",
    "1. **Binary images**: Pixels are either 0 or 1\n",
    "2. **Grayscale images**: Pixels have intensity values (0-255)\n",
    "3. **Color images**: Pixels have multiple channels (e.g., RGB)\n",
    "\n",
    "Let's load and examine an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread('../data/sample.jpg')\n",
    "\n",
    "# Check image properties\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image data type: {img.dtype}\")\n",
    "print(f\"Image size: {img.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Color Spaces\n",
    "\n",
    "### RGB Color Space\n",
    "RGB represents colors as combinations of Red, Green, and Blue channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the image into its RGB channels\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "# Display each channel\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(r, cmap='Reds')\n",
    "axes[0].set_title('Red Channel')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(g, cmap='Greens')\n",
    "axes[1].set_title('Green Channel')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(b, cmap='Blues')\n",
    "axes[2].set_title('Blue Channel')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grayscale Conversion\n",
    "\n",
    "Converting to grayscale reduces the image to a single channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Grayscale image shape: {gray.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV Color Space\n",
    "\n",
    "HSV represents colors in terms of Hue, Saturation, and Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HSV\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "# Display HSV channels\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(h, cmap='hsv')\n",
    "axes[0].set_title('Hue')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(s, cmap='gray')\n",
    "axes[1].set_title('Saturation')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(v, cmap='gray')\n",
    "axes[2].set_title('Value')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Image Processing Operations\n",
    "\n",
    "### Image Blending\n",
    "\n",
    "Blending combines two images with specified weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second image (we'll make a copy and modify it)\n",
    "img2 = img.copy()\n",
    "img2 = cv2.addWeighted(img2, 0.5, np.ones_like(img2)*255, 0.5, 0)\n",
    "\n",
    "# Blend the images\n",
    "blended = cv2.addWeighted(img, 0.7, img2, 0.3, 0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Modified')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(blended, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Blended')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Transformations\n",
    "\n",
    "#### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation matrix\n",
    "M = np.float32([[1, 0, 100], [0, 1, 50]])\n",
    "translated = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(translated, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Translated')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rotation matrix\n",
    "center = (img.shape[1]//2, img.shape[0]//2)\n",
    "M = cv2.getRotationMatrix2D(center, 45, 1.0)\n",
    "rotated = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(rotated, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Rotated')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the image\n",
    "scaled = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(f'Original ({img.shape[1]}x{img.shape[0]})')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(scaled, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Scaled ({scaled.shape[1]}x{scaled.shape[0]})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Filtering and Convolution\n",
    "\n",
    "### Blur Filters\n",
    "\n",
    "#### Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging filter\n",
    "blur = cv2.blur(img, (5, 5))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(blur, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Averaging Blur')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian blur\n",
    "gaussian = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(gaussian, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Gaussian Blur')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median blur\n",
    "median = cv2.medianBlur(img, 5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(median, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Median Blur')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Edge Detection\n",
    "\n",
    "### Sobel Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale for edge detection\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Sobel X and Y\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "# Combined Sobel\n",
    "sobel_combined = np.sqrt(sobelx**2 + sobely**2)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axes[0, 0].imshow(gray, cmap='gray')\n",
    "axes[0, 0].set_title('Grayscale')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(sobelx, cmap='gray')\n",
    "axes[0, 1].set_title('Sobel X')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(sobely, cmap='gray')\n",
    "axes[1, 0].set_title('Sobel Y')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(sobel_combined, cmap='gray')\n",
    "axes[1, 1].set_title('Sobel Combined')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny edge detection\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(gray, cmap='gray')\n",
    "axes[0].set_title('Grayscale')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(edges, cmap='gray')\n",
    "axes[1].set_title('Canny Edges')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Histograms and Thresholding\n",
    "\n",
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate histogram\n",
    "hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(hist)\n",
    "plt.title('Grayscale Histogram')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding\n",
    "\n",
    "#### Simple Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple thresholding\n",
    "ret, thresh1 = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(gray, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(thresh1, cmap='gray')\n",
    "axes[1].set_title('Binary Threshold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(thresh2, cmap='gray')\n",
    "axes[2].set_title('Inverse Binary Threshold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive thresholding\n",
    "adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(gray, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(adaptive_thresh, cmap='gray')\n",
    "axes[1].set_title('Adaptive Threshold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, we've covered:\n",
    "1. Image representation and color spaces\n",
    "2. Basic image processing operations\n",
    "3. Image filtering and convolution\n",
    "4. Edge detection techniques\n",
    "5. Histogram analysis and thresholding\n",
    "\n",
    "These foundational concepts form the building blocks for more advanced computer vision techniques. In the next module, we'll explore classical computer vision techniques like feature detection and matching."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}