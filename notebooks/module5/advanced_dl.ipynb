{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: Advanced Deep Learning for Computer Vision\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this module, you should be able to:\n",
    "- Implement state-of-the-art CNN architectures\n",
    "- Build object detection systems\n",
    "- Perform semantic segmentation\n",
    "- Create generative models\n",
    "- Apply attention mechanisms in vision tasks\n",
    "\n",
    "## Topics Covered\n",
    "- Advanced CNN architectures (ResNet, Inception, EfficientNet)\n",
    "- Object detection (R-CNN, YOLO, SSD)\n",
    "- Semantic segmentation (U-Net, Mask R-CNN)\n",
    "- Generative models (GANs, VAEs)\n",
    "- Attention mechanisms and transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Advanced CNN Architectures\n",
    "\n",
    "### ResNet (Residual Networks)\n",
    "\n",
    "ResNets address the vanishing gradient problem through skip connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Residual block implementation\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Skip connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        # Skip connection\n",
    "        out += self.shortcut(residual)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Visualize ResNet architecture concept\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.text(0.5, 0.9, 'ResNet Residual Block', ha='center', va='center', fontsize=16, transform=ax.transAxes)\n",
    "\n",
    "# Input\n",
    "ax.text(0.2, 0.8, 'Input', ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "\n",
    "# Main path\n",
    "ax.text(0.4, 0.7, 'Conv1\\nBN\\nReLU', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\"))\n",
    "ax.text(0.6, 0.7, 'Conv2\\nBN', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\"))\n",
    "\n",
    "# Skip connection\n",
    "ax.text(0.4, 0.5, 'Shortcut\\n(Conv+BN if needed)', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\"))\n",
    "\n",
    "# Output\n",
    "ax.text(0.8, 0.6, 'Add\\nReLU', ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
    "\n",
    "# Connections\n",
    "ax.annotate('', xy=(0.3, 0.8), xytext=(0.2, 0.8), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "ax.annotate('', xy=(0.5, 0.7), xytext=(0.4, 0.7), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "ax.annotate('', xy=(0.7, 0.7), xytext=(0.6, 0.7), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "ax.annotate('', xy=(0.8, 0.6), xytext=(0.7, 0.7), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "ax.annotate('', xy=(0.5, 0.5), xytext=(0.3, 0.8), arrowprops=dict(arrowstyle=\"->\", lw=1, color='red'))\n",
    "ax.annotate('', xy=(0.8, 0.6), xytext=(0.5, 0.5), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "\n",
    "ax.text(0.5, 0.3, 'Output', ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "ax.annotate('', xy=(0.5, 0.3), xytext=(0.8, 0.6), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "\n",
    "ax.set_title('ResNet Architecture Concept')\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"ResNet Key Concepts:\")\n",
    "print(\"1. Skip connections help with gradient flow\")\n",
    "print(\"2. Enables training of very deep networks\")\n",
    "print(\"3. Addresses vanishing gradient problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Object Detection\n",
    "\n",
    "### YOLO (You Only Look Once)\n",
    "\n",
    "YOLO is a real-time object detection system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual overview of YOLO\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 10))\n",
    "ax.text(0.5, 0.95, 'YOLO Object Detection Concept', ha='center', va='center', fontsize=18, transform=ax.transAxes)\n",
    "\n",
    "# Input image\n",
    "ax.text(0.1, 0.8, 'Input Image\\n(448×448×3)', ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "\n",
    "# Grid division\n",
    "ax.text(0.3, 0.8, 'Divide into\\nS×S grid\\n(e.g., 7×7)', ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\"))\n",
    "\n",
    "# CNN backbone\n",
    "ax.text(0.5, 0.8, 'CNN Backbone\\n(Feature extraction)', ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\"))\n",
    "\n",
    "# Detection\n",
    "ax.text(0.7, 0.8, 'Detection Layer\\n(S×S×(B×5+C))', ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
    "\n",
    "# Output\n",
    "ax.text(0.9, 0.8, 'Bounding Boxes\\n+ Class Probabilities', ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightpink\"))\n",
    "\n",
    "# Connections\n",
    "for i in range(4):\n",
    "    ax.annotate('', xy=(0.3+0.2*i, 0.8), xytext=(0.1+0.2*i, 0.8), arrowprops=dict(arrowstyle=\"->\", lw=2))\n",
    "\n",
    "# Detailed explanation\n",
    "ax.text(0.2, 0.6, 'Grid Cell Concept:', ha='center', va='center', fontsize=14, transform=ax.transAxes, weight='bold')\n",
    "ax.text(0.2, 0.5, 'Each grid cell:\\n- Predicts B bounding boxes\\n- Confidence scores\\n- Class probabilities', \n",
    "        ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "\n",
    "ax.text(0.5, 0.6, 'Bounding Box:\\n- x, y (center coordinates)\\n- w, h (width, height)\\n- Confidence score', \n",
    "        ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "\n",
    "ax.text(0.8, 0.6, 'Class Prediction:\\n- Probability for\\n  each of C classes', \n",
    "        ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "\n",
    "# Loss function\n",
    "ax.text(0.5, 0.3, 'YOLO Loss Function:\\nLocalization + Confidence + Classification', \n",
    "        ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcyan\"))\n",
    "\n",
    "ax.set_title('YOLO Architecture Overview')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"YOLO Advantages:\")\n",
    "print(\"1. Real-time detection\")\n",
    "print(\"2. Global context consideration\")\n",
    "print(\"3. End-to-end training\")\n",
    "print(\"\\nYOLO Limitations:\")\n",
    "print(\"1. Struggles with small objects\")\n",
    "print(\"2. Limited to a fixed number of bounding boxes per grid cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Semantic Segmentation\n",
    "\n",
    "### U-Net\n",
    "\n",
    "U-Net is a convolutional network architecture for biomedical image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize U-Net architecture\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12))\n",
    "ax.text(0.5, 0.98, 'U-Net Architecture', ha='center', va='center', fontsize=18, transform=ax.transAxes)\n",
    "\n",
    "# Contracting path (left side)\n",
    "contracting_blocks = [\n",
    "    (0.1, 0.8, 'Input\\nImage'),\n",
    "    (0.2, 0.7, 'Conv+ReLU\\nConv+ReLU\\nMaxPool'),\n",
    "    (0.3, 0.6, 'Conv+ReLU\\nConv+ReLU\\nMaxPool'),\n",
    "    (0.4, 0.5, 'Conv+ReLU\\nConv+ReLU\\nMaxPool'),\n",
    "    (0.5, 0.4, 'Conv+ReLU\\nConv+ReLU\\nMaxPool')\n",
    "]\n",
    "\n",
    "# Bottleneck\n",
    "bottleneck = (0.6, 0.3, 'Conv+ReLU\\nConv+ReLU')\n",
    "\n",
    "# Expanding path (right side)\n",
    "expanding_blocks = [\n",
    "    (0.7, 0.4, 'UpConv\\nConcat\\nConv+ReLU\\nConv+ReLU'),\n",
    "    (0.8, 0.5, 'UpConv\\nConcat\\nConv+ReLU\\nConv+ReLU'),\n",
    "    (0.9, 0.6, 'UpConv\\nConcat\\nConv+ReLU\\nConv+ReLU'),\n",
    "    (1.0, 0.7, 'UpConv\\nConcat\\nConv+ReLU\\nConv+ReLU')\n",
    "]\n",
    "\n",
    "# Output\n",
    "output_block = (1.1, 0.8, '1x1 Conv\\nSegmentation\\nMap')\n",
    "\n",
    "# Draw contracting path\n",
    "for i, (x, y, text) in enumerate(contracting_blocks):\n",
    "    ax.text(x, y, text, ha='center', va='center', fontsize=8, transform=ax.transAxes,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "    if i > 0:\n",
    "        ax.annotate('', xy=(x, y), xytext=(contracting_blocks[i-1][0], contracting_blocks[i-1][1]), \n",
    "                    arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "\n",
    "# Draw bottleneck\n",
    "ax.text(bottleneck[0], bottleneck[1], bottleneck[2], ha='center', va='center', fontsize=8, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\"))\n",
    "ax.annotate('', xy=(bottleneck[0], bottleneck[1]), xytext=(contracting_blocks[-1][0], contracting_blocks[-1][1]), \n",
    "            arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "\n",
    "# Draw expanding path\n",
    "prev_x, prev_y = bottleneck[0], bottleneck[1]\n",
    "for i, (x, y, text) in enumerate(expanding_blocks):\n",
    "    ax.text(x, y, text, ha='center', va='center', fontsize=8, transform=ax.transAxes,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\"))\n",
    "    ax.annotate('', xy=(x, y), xytext=(prev_x, prev_y), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "    \n",
    "    # Skip connections\n",
    "    if i < len(contracting_blocks) - 1:\n",
    "        skip_x, skip_y = contracting_blocks[-(i+2)][0], contracting_blocks[-(i+2)][1]\n",
    "        ax.annotate('', xy=(x-0.05, y+0.05), xytext=(skip_x+0.05, skip_y-0.05), \n",
    "                    arrowprops=dict(arrowstyle=\"->\", lw=1, color='red', linestyle='dashed'))\n",
    "        ax.text((x+skip_x)/2, (y+skip_y)/2, 'Skip\\nConnection', ha='center', va='center', \n",
    "                fontsize=6, transform=ax.transAxes, color='red')\n",
    "    \n",
    "    prev_x, prev_y = x, y\n",
    "\n",
    "# Draw output\n",
    "ax.text(output_block[0], output_block[1], output_block[2], ha='center', va='center', fontsize=8, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
    "ax.annotate('', xy=(output_block[0], output_block[1]), xytext=(expanding_blocks[-1][0], expanding_blocks[-1][1]), \n",
    "            arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "\n",
    "# U-Net characteristics\n",
    "ax.text(0.3, 0.1, 'Characteristics:', ha='center', va='center', fontsize=14, transform=ax.transAxes, weight='bold')\n",
    "ax.text(0.3, 0.05, '• Contracting path captures context\\n• Expanding path enables precise localization\\n• Skip connections combine global and local information', \n",
    "        ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "\n",
    "ax.set_title('U-Net Architecture Diagram')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"U-Net Key Features:\")\n",
    "print(\"1. Symmetrical U-shaped architecture\")\n",
    "print(\"2. Skip connections between contracting and expanding paths\")\n",
    "print(\"3. Excellent for biomedical image segmentation\")\n",
    "print(\"4. Works well with limited training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generative Models\n",
    "\n",
    "### GANs (Generative Adversarial Networks)\n",
    "\n",
    "GANs consist of two neural networks competing against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN architecture visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 10))\n",
    "ax.text(0.5, 0.95, 'Generative Adversarial Network (GAN)', ha='center', va='center', fontsize=18, transform=ax.transAxes)\n",
    "\n",
    "# Generator\n",
    "ax.text(0.2, 0.7, 'Generator\\n\\n- Takes random noise\\n- Generates fake images\\n- Tries to fool Discriminator', \n",
    "        ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\"))\n",
    "\n",
    "# Discriminator\n",
    "ax.text(0.8, 0.7, 'Discriminator\\n\\n- Takes real/fake images\\n- Outputs probability\\n- Tries to detect fakes', \n",
    "        ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
    "\n",
    "# Random noise\n",
    "ax.text(0.1, 0.5, 'Random Noise\\n(z ~ N(0,1))', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "\n",
    "# Generated image\n",
    "ax.text(0.35, 0.5, 'Generated Image\\nG(z)', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\"))\n",
    "\n",
    "# Real images\n",
    "ax.text(0.65, 0.5, 'Real Images\\nfrom dataset', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "\n",
    "# Discriminator output\n",
    "ax.text(0.9, 0.5, 'Probability\\nReal/Fake', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightpink\"))\n",
    "\n",
    "# Connections\n",
    "ax.annotate('', xy=(0.25, 0.65), xytext=(0.15, 0.55), arrowprops=dict(arrowstyle=\"->\", lw=2))\n",
    "ax.annotate('', xy=(0.45, 0.55), xytext=(0.25, 0.65), arrowprops=dict(arrowstyle=\"->\", lw=2))\n",
    "ax.annotate('', xy=(0.55, 0.55), xytext=(0.75, 0.65), arrowprops=dict(arrowstyle=\"->\", lw=2))\n",
    "ax.annotate('', xy=(0.85, 0.65), xytext=(0.55, 0.55), arrowprops=dict(arrowstyle=\"->\", lw=2, color='red'))\n",
    "ax.annotate('', xy=(0.85, 0.65), xytext=(0.75, 0.55), arrowprops=dict(arrowstyle=\"->\", lw=2, color='blue'))\n",
    "ax.annotate('', xy=(0.95, 0.55), xytext=(0.85, 0.65), arrowprops=dict(arrowstyle=\"->\", lw=2))\n",
    "\n",
    "# Loss functions\n",
    "ax.text(0.3, 0.3, 'Generator Loss:\\nminimize -log(D(G(z)))', \n",
    "        ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "\n",
    "ax.text(0.7, 0.3, 'Discriminator Loss:\\nmaximize log(D(x)) + log(1-D(G(z)))', \n",
    "        ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "\n",
    "# Minimax game\n",
    "ax.text(0.5, 0.15, 'Minimax Game:\\nmin_G max_D V(D,G) = E[log(D(x))] + E[log(1-D(G(z)))]', \n",
    "        ha='center', va='center', fontsize=12, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcyan\"))\n",
    "\n",
    "ax.set_title('GAN Architecture and Training Process')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"GAN Training Dynamics:\")\n",
    "print(\"1. Generator tries to create realistic images\")\n",
    "print(\"2. Discriminator tries to distinguish real from fake\")\n",
    "print(\"3. Equilibrium: Generator produces realistic images that fool Discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attention Mechanisms and Transformers\n",
    "\n",
    "### Vision Transformers (ViT)\n",
    "\n",
    "Vision Transformers apply the transformer architecture to image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision Transformer concept\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 12))\n",
    "ax.text(0.5, 0.98, 'Vision Transformer (ViT) Concept', ha='center', va='center', fontsize=18, transform=ax.transAxes)\n",
    "\n",
    "# Input image\n",
    "ax.text(0.1, 0.8, 'Input Image\\n(224×224×3)', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "\n",
    "# Patch splitting\n",
    "ax.text(0.25, 0.8, 'Split into Patches\\n(16×16×3 each)', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\"))\n",
    "\n",
    "# Linear projection\n",
    "ax.text(0.4, 0.8, 'Linear Projection\\n(Patch Embeddings)', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\"))\n",
    "\n",
    "# Position embeddings\n",
    "ax.text(0.55, 0.8, 'Add Position\\nEmbeddings', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\"))\n",
    "\n",
    "# Class token\n",
    "ax.text(0.7, 0.8, 'Add Class Token', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightpink\"))\n",
    "\n",
    "# Transformer encoder\n",
    "ax.text(0.85, 0.8, 'Transformer\\nEncoder (L blocks)', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcyan\"))\n",
    "\n",
    "# MLP head\n",
    "ax.text(0.85, 0.6, 'MLP Head\\n(Classification)', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "\n",
    "# Connections\n",
    "for i in range(5):\n",
    "    ax.annotate('', xy=(0.25+0.15*i, 0.8), xytext=(0.1+0.15*i, 0.8), arrowprops=dict(arrowstyle=\"->\", lw=2))\n",
    "ax.annotate('', xy=(0.85, 0.7), xytext=(0.85, 0.7), arrowprops=dict(arrowstyle=\"->\", lw=2))\n",
    "ax.annotate('', xy=(0.85, 0.6), xytext=(0.85, 0.7), arrowprops=dict(arrowstyle=\"->\", lw=2))\n",
    "\n",
    "# Transformer encoder details\n",
    "ax.text(0.5, 0.5, 'Transformer Encoder Block:', ha='center', va='center', fontsize=14, transform=ax.transAxes, weight='bold')\n",
    "\n",
    "# Multi-head attention\n",
    "ax.text(0.3, 0.4, 'Multi-Head\\nSelf-Attention', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "\n",
    "# Layer norm\n",
    "ax.text(0.4, 0.4, 'Layer\\nNorm', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\"))\n",
    "\n",
    "# MLP\n",
    "ax.text(0.6, 0.4, 'MLP\\n(2 layers)', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\"))\n",
    "\n",
    "# Layer norm\n",
    "ax.text(0.7, 0.4, 'Layer\\nNorm', ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\"))\n",
    "\n",
    "# Connections\n",
    "ax.annotate('', xy=(0.35, 0.4), xytext=(0.3, 0.4), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "ax.annotate('', xy=(0.5, 0.4), xytext=(0.4, 0.4), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "ax.annotate('', xy=(0.65, 0.4), xytext=(0.6, 0.4), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "ax.annotate('', xy=(0.7, 0.4), xytext=(0.65, 0.4), arrowprops=dict(arrowstyle=\"->\", lw=1))\n",
    "\n",
    "# Skip connections\n",
    "ax.annotate('', xy=(0.4, 0.45), xytext=(0.3, 0.45), arrowprops=dict(arrowstyle=\"->\", lw=1, color='red'))\n",
    "ax.text(0.35, 0.47, 'Skip', ha='center', va='center', fontsize=8, transform=ax.transAxes, color='red')\n",
    "\n",
    "ax.annotate('', xy=(0.7, 0.45), xytext=(0.6, 0.45), arrowprops=dict(arrowstyle=\"->\", lw=1, color='red'))\n",
    "ax.text(0.65, 0.47, 'Skip', ha='center', va='center', fontsize=8, transform=ax.transAxes, color='red')\n",
    "\n",
    "# Attention mechanism detail\n",
    "ax.text(0.2, 0.2, 'Self-Attention:\\nQ = XW_Q\\nK = XW_K\\nV = XW_V\\nAttention(Q,K,V) = softmax(QK^T/√d_k)V', \n",
    "        ha='center', va='center', fontsize=9, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "\n",
    "# Benefits\n",
    "ax.text(0.7, 0.2, 'ViT Benefits:\\n- Global attention\\n- Sequence modeling\\n- Transfer learning\\n- Scalability', \n",
    "        ha='center', va='center', fontsize=10, transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcyan\"))\n",
    "\n",
    "ax.set_title('Vision Transformer Architecture')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Vision Transformer Key Concepts:\")\n",
    "print(\"1. Treats images as sequences of patches\")\n",
    "print(\"2. Uses self-attention to model global relationships\")\n",
    "print(\"3. Competitive with CNNs when trained on large datasets\")\n",
    "print(\"4. Better transfer learning capabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, we've explored:\n",
    "1. Advanced CNN architectures like ResNet with skip connections\n",
    "2. Object detection systems including YOLO\n",
    "3. Semantic segmentation with U-Net\n",
    "4. Generative models like GANs\n",
    "5. Attention mechanisms and Vision Transformers\n",
    "\n",
    "These advanced techniques represent the current state-of-the-art in computer vision and form the foundation for many modern applications. In the final module, we'll explore specialized applications and cutting-edge research directions in computer vision."
   ]
  }
 ],
 \"metadata\": {
  \"kernelspec\": {
   \"display_name\": \"Python 3\",
   \"language\": \"python\",
   \"name\": \"python3\"
  },
  \"language_info\": {
   \"codemirror_mode\": {
    \"name\": \"ipython\",
    \"version\": 3
   },
   \"file_extension\": \".py\",
   \"mimetype\": \"text/x-python\",
   \"name\": \"python\",
   \"nbconvert_exporter\": \"python\",
   \"pygments_lexer\": \"ipython3\",
   \"version\": \"3.8.5\"
  }
 },
 \"nbformat\": 4,
 \"nbformat_minor\": 4
}