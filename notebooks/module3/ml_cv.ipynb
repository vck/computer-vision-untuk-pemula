{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Machine Learning for Computer Vision\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this module, you should be able to:\n",
    "- Extract meaningful features from images\n",
    "- Apply traditional ML algorithms to computer vision tasks\n",
    "- Implement image classification systems\n",
    "- Perform image segmentation using clustering\n",
    "- Apply dimensionality reduction techniques\n",
    "\n",
    "## Topics Covered\n",
    "- Traditional ML algorithms for image classification\n",
    "- Feature extraction techniques (HOG, LBP)\n",
    "- Support Vector Machines (SVM) for image classification\n",
    "- K-Means clustering for image segmentation\n",
    "- Principal Component Analysis (PCA) for dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Extraction Techniques\n",
    "\n",
    "### HOG (Histogram of Oriented Gradients)\n",
    "\n",
    "HOG is a feature descriptor used in computer vision and image processing for object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# Create a sample image\n",
    "img = np.zeros((200, 200), dtype=np.uint8)\n",
    "cv2.rectangle(img, (50, 50), (150, 150), 255, -1)\n",
    "cv2.circle(img, (100, 100), 30, 128, -1)\n",
    "\n",
    "# Extract HOG features\n",
    "fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(2, 2), visualize=True, channel_axis=None)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(img, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(hog_image, cmap='gray')\n",
    "axes[1].set_title('HOG Features')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"HOG feature vector shape: {fd.shape}\")\n",
    "print(f\"HOG image shape: {hog_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP (Local Binary Patterns)\n",
    "\n",
    "LBP is a type of visual descriptor used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# Parameters for LBP\n",
    "radius = 3\n",
    "n_points = 8 * radius\n",
    "\n",
    "# Compute LBP\n",
    "lbp = local_binary_pattern(img, n_points, radius, method='uniform')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(img, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(lbp, cmap='gray')\n",
    "axes[1].set_title('LBP Features')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"LBP image shape: {lbp.shape}\")\n",
    "print(f\"Unique LBP values: {len(np.unique(lbp))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machines (SVM) for Image Classification\n",
    "\n",
    "Let's create a simple image classification example using SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a simple dataset of shapes\n",
    "def create_shape_dataset(n_samples=200):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        img = np.zeros((64, 64), dtype=np.uint8)\n",
    "        \n",
    "        if i % 2 == 0:  // Circle\n",
    "            center = (np.random.randint(20, 44), np.random.randint(20, 44))\n",
    "            radius = np.random.randint(8, 15)\n",
    "            cv2.circle(img, center, radius, 255, -1)\n",
    "            y.append(0)  // Class 0: Circle\n",
    "        else:  // Rectangle\n",
    "            pt1 = (np.random.randint(10, 25), np.random.randint(10, 25))\n",
    "            pt2 = (np.random.randint(35, 50), np.random.randint(35, 50))\n",
    "            cv2.rectangle(img, pt1, pt2, 255, -1)\n",
    "            y.append(1)  // Class 1: Rectangle\n",
    "            \n",
    "        // Extract HOG features\n",
    "        fd = hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                 cells_per_block=(2, 2), channel_axis=None)\n",
    "        X.append(fd)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "// Generate dataset\n",
    "X, y = create_shape_dataset(200)\n",
    "\n",
    "// Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Train SVM classifier\n",
    "clf = svm.SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "// Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "// Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Circle', 'Rectangle']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Means Clustering for Image Segmentation\n",
    "\n",
    "K-Means can be used for image segmentation by clustering pixels based on their color values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "// Create a sample image with different color regions\n",
    "img_color = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "img_color[0:100, 0:100] = [255, 0, 0]      // Red quadrant\n",
    "img_color[0:100, 100:200] = [0, 255, 0]    // Green quadrant\n",
    "img_color[100:200, 0:100] = [0, 0, 255]    // Blue quadrant\n",
    "img_color[100:200, 100:200] = [255, 255, 0] // Yellow quadrant\n",
    "\n",
    "// Add some noise\n",
    "noise = np.random.randint(-20, 20, img_color.shape, dtype=np.int16)\n",
    "img_color = np.clip(img_color.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "// Reshape image to be a list of pixels\n",
    "pixel_list = img_color.reshape((-1, 3))\n",
    "\n",
    "// Apply K-Means clustering\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(pixel_list)\n",
    "\n",
    "// Get cluster assignments for each pixel\n",
    "clustered = kmeans.cluster_centers_[kmeans.labels_]\n",
    "clustered_img = clustered.reshape(img_color.shape).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(clustered_img, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('K-Means Segmented Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of clusters: {k}\")\n",
    "print(f\"Cluster centers:\\n{kmeans.cluster_centers_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Principal Component Analysis (PCA) for Dimensionality Reduction\n",
    "\n",
    "PCA can be used to reduce the dimensionality of image data while preserving important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "// Create a dataset of face-like images\n",
    "def create_face_dataset(n_samples=50):\n",
    "    X = []\n",
    "    for i in range(n_samples):\n",
    "        img = np.zeros((64, 64), dtype=np.uint8)\n",
    "        \n",
    "        // Add some variation to create different \"faces\"\n",
    "        // Face (ellipse)\n",
    "        center = (32 + np.random.randint(-5, 5), 32 + np.random.randint(-5, 5))\n",
    "        axes = (20 + np.random.randint(-3, 3), 25 + np.random.randint(-3, 3))\n",
    "        cv2.ellipse(img, center, axes, 0, 0, 360, 255, -1)\n",
    "        \n",
    "        // Eyes\n",
    "        eye_y = center[1] - 8\n",
    "        left_eye_x = center[0] - 8 + np.random.randint(-2, 2)\n",
    "        right_eye_x = center[0] + 8 + np.random.randint(-2, 2)\n",
    "        cv2.circle(img, (left_eye_x, eye_y), 3, 0, -1)\n",
    "        cv2.circle(img, (right_eye_x, eye_y), 3, 0, -1)\n",
    "        \n",
    "        // Mouth (ellipse)\n",
    "        mouth_y = center[1] + 10\n",
    "        mouth_x = center[0] + np.random.randint(-2, 2)\n",
    "        mouth_axes = (8 + np.random.randint(-2, 2), 3 + np.random.randint(-1, 1))\n",
    "        cv2.ellipse(img, (mouth_x, mouth_y), mouth_axes, 0, 0, 180, 0, -1)\n",
    "        \n",
    "        X.append(img.flatten())\n",
    "    \n",
    "    return np.array(X)\n",
    "\n",
    "// Generate face dataset\n",
    "face_data = create_face_dataset(50)\n",
    "\n",
    "print(f\"Face dataset shape: {face_data.shape}\")\n",
    "print(f\"Each image is {int(np.sqrt(face_data.shape[1]))}x{int(np.sqrt(face_data.shape[1]))} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Apply PCA\n",
    "n_components = 50  // Reduce from 4096 to 50 dimensions\n",
    "pca = PCA(n_components=n_components)\n",
    "face_data_pca = pca.fit_transform(face_data)\n",
    "\n",
    "// Reconstruct images from PCA components\n",
    "face_data_reconstructed = pca.inverse_transform(face_data_pca)\n",
    "\n",
    "print(f\"Original data shape: {face_data.shape}\")\n",
    "print(f\"PCA transformed shape: {face_data_pca.shape}\")\n",
    "print(f\"Reconstructed data shape: {face_data_reconstructed.shape}\")\n",
    "print(f\"Variance explained by {n_components} components: {np.sum(pca.explained_variance_ratio_):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Visualize original vs reconstructed images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i in range(5):\n",
    "    // Original image\n",
    "    axes[0, i].imshow(face_data[i].reshape(64, 64), cmap='gray')\n",
    "    axes[0, i].set_title('Original')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    // Reconstructed image\n",
    "    axes[1, i].imshow(face_data_reconstructed[i].reshape(64, 64), cmap='gray')\n",
    "    axes[1, i].set_title('Reconstructed')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('PCA for Image Compression')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Visualize the first few principal components\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for i in range(5):\n",
    "    component = pca.components_[i].reshape(64, 64)\n",
    "    axes[i].imshow(component, cmap='RdBu')\n",
    "    axes[i].set_title(f'PC {i+1}\\n({pca.explained_variance_ratio_[i]:.2%} variance)')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Principal Components')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, we've covered:\n",
    "1. Feature extraction techniques (HOG, LBP)\n",
    "2. Image classification using Support Vector Machines\n",
    "3. Image segmentation with K-Means clustering\n",
    "4. Dimensionality reduction using Principal Component Analysis\n",
    "\n",
    "These traditional machine learning approaches provide a strong foundation for understanding modern deep learning techniques. In the next module, we'll dive into deep learning and neural networks for computer vision tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}